# ====== APP / SERVER ======
FLASK_ENV=production
PORT=5000

# ====== KNOWLEDGE BASE ======
# Cartella “magna” (scansione ricorsiva di sottocartelle e file)
KNOWLEDGE_DIR=./documenti_gTab

# Soglia di similarità (0–100). Se non trovi match, prova 55–60.
SIMILARITY_THRESHOLD=65

# Quanti documenti pertinenti mostrare in risposta
MAX_MATCHES=6

# ====== (OPZIONALE) FALLBACK LLM ======
# Se vuoi usare il fallback con OpenAI, imposta la chiave:
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx
# MODEL_NAME=gpt-4o-mini
# ====== LLM DETERMINISTICO (per risposte identiche PC/Cell) ======
# Modello “pinnato”
MODEL_NAME=gpt-5.0
# Sampling “anti-casualità”
OPENAI_TEMPERATURE=0
TOP_P=1
PRESENCE_PENALTY=0
FREQUENCY_PENALTY=0

# Varianti lowercase (se il tuo codice le legge così, copriamo anche questo caso)
top_p=1
presence_penalty=0
frequency_penalty=0
# ====== LLM DETERMINISTICO (stesse risposte PC/Cell) ======
# Modello fisso
OPENAI_MODEL=gpt-5.0
MODEL_NAME=gpt-5.0

# Sampling anti-casualità
OPENAI_TEMPERATURE=0
TEMPERATURE=0
TOP_P=1
top_p=1
PRESENCE_PENALTY=0
presence_penalty=0
FREQUENCY_PENALTY=0
frequency_penalty=0
